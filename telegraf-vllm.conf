# Global tags can be specified here in key="value" format.
[global_tags]

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "2s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 100000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "1s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Override default hostname, if empty use os.Hostname()
  # hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true


# Configuration for sending metrics to InfluxDB 2.0
[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  urls = ["https://[YOUR-INFLUXDB-URL.COM]"]

  ## Token for authentication.
  token = "[YOUR_INFLUXDB_TOKEN_HERE]"

  ## Organization is the name of the organization you wish to write to.
  organization = "[YOUR_ORGANIZATION_NAME]"

  ## Destination bucket to write into.
  bucket = "[YOUR_BUCKET_NAME]"

  ## Timeout for HTTP messages.
  timeout = "5s"


# Filter metrics by the given criteria
[[processors.filter]]
    ## Default action if no rule applies
    default = "pass"

    ## Rules to apply on the incoming metrics (multiple rules are possible)
    ## The rules are evaluated in order and the first matching rule is applied.
    ## In case no rule matches the "default" is applied.
    ## All filter criteria in a rule must apply for the rule to match the metric
    ## i.e. the criteria are combined by a logical AND. If a criterion is
    ## omitted it is NOT applied at all and ignored.
    [[processors.filter.rule]]
        ## List of metric names to match including glob expressions
        # name = []

        ## List of tag key/values pairs to match including glob expressions
        ## ALL given tags keys must exist and at least one value must match
        ## for the metric to match the rule.
        # tags = {}

        ## List of field keys to match including glob expressions
        ## At least one field must exist for the metric to match the rule.
        fields = ["process_cpu_seconds_total", "process_open_fds", "process_max_fds", "python_info"]

        ## Action to apply for this rule
        ## "pass" will keep the metric and pass it on, while "drop" will remove
        ## the metric
        action = "drop"


# Read metrics from one or many prometheus clients
[[inputs.prometheus]]
  ## An array of urls to scrape metrics from.
  urls = ["http://[YOUR-VLLM-ENDPOINT.com]:[PORT]/metrics"]

  ## Metric version controls the mapping from Prometheus metrics into Telegraf metrics.
  ## See "Metric Format Configuration" in plugins/inputs/prometheus/README.md for details.
  ## Valid options: 1, 2
  metric_version = 2
